\documentclass{article}

\PassOptionsToPackage{numbers, compress}{natbib}

\usepackage[final]{proposal_neurips_2021}

\bibliographystyle{abbrvnat}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}

\title{Proposal: DINO Methods for Style Transfer}

\author{
  Sacha Goldman \\
  Department of Computer Science\\ 
  Department of Mathematics\\
  University of Toronto\\
  Toronto, ON M5S 1A1 \\
  \texttt{sacha.goldman@mail.utoronto.ca} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
Style transfer is the problem of changing an image's artistic style while maintaining its ``content'', namely the object it depicts. Conventional models use CNN to extract features from an image, take in another image indicating the desired artistic style, and attempt to apply that style to the features of the original input image. However, it has been shown that due to the locality resulting from shared weights, CNN struggles to capture global information of input images and suffers from feature losses \cite{ImageStyleTransformer}. To resolve these issues, models that use Transformers instead of CNN for feature and style extraction have been proposed and shown improved results \cite{ImageStyleTransformer}. The authors of \cite{ImageStyleTransformer} use 


\section{Related Works}



\section{Method}

We have four different idea for bringing the success of the DINO method to the domain of style transfer.

\subsection{Frozen DINO Content Encoder}

We replace the content encoder with a transformer trained by DINO and then train the style and decoders using the regular style transfer training paradigm. The idea being that the DINO models robust features vectors may act as powerful abstractions of the information that can be decoded with the new style.

\subsection{DINO Weight Initialized Content Encoder}

We use a transformer trained by DINO as the initial weights for the content encoder but we run the style transfer training paradigm on both encoders and the decoder, effectively using the weights from DINO as initial weights. We expect this to converge to a different optima because transformers have many local optima. We hope that the robust abstractions from the DINO training process lead to better style transfer.

\subsection{DINO Training for Encoders}



\subsection{Modified DINO Training for Encoders}



\medskip

% Our current sources
\nocite{*}

\bibliography{bib}

\end{document}