\documentclass{article}

\PassOptionsToPackage{numbers, compress}{natbib}

\usepackage[final]{proposal_neurips_2021}

\bibliographystyle{abbrvnat}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}

\title{Proposal: DINO Methods for Style Transfer}

\author{
  Sacha Goldman \\
  Department of Computer Science\\ 
  Department of Mathematics\\
  University of Toronto\\
  Toronto, ON M5S 1A1 \\
  \texttt{sacha.goldman@mail.utoronto.ca} \\
  \And
  Yuchong Zhang \\
  Department of Computer Science \\
  Department of Mathematics \\
  University of Toronoto \\
  Toronto, ON, M5S 1A1 \\
  \texttt{yuchongz.zhang@mail.utoronto.ca} \\
  % \And
  % Coauthor \\
  % Affiliation \\
  % Address \\
  % \texttt{email} \\
}

\begin{document}

\maketitle

\begin{abstract}

\end{abstract}

\section{Introduction}
Style transfer is the problem of changing an image's artistic style while maintaining its ``content'', namely the object it depicts. Conventional models use CNN to extract features from an image, take in another image indicating the desired artistic style, and attempt to apply that style to the features of the original input image. However, it has been shown that due to the locality resulting from shared weights, CNN struggles to capture global information of input images and suffers from feature losses \cite{ImageStyleTransformer}. To resolve these issues, models that use Transformers instead of CNN for feature and style extraction have been proposed and shown improved results \cite{ImageStyleTransformer}. The model StyTr proposed in \cite{ImageStyleTransformer} takes in a content image and a style image, uses two transformer encoders to capture the content and style, then renders the content with that style using a thrid transformer decoder. In our project, we will substitute the DINO model proposed in \cite{DINO} for the encoder components and explore the effects on the task of style transfer. DINO method is good at extracting content even if the input images are distorted or partial. So in particular, we will implement the models and conduct experiments to explore the following questions:
\begin{enumerate}
  \item By using DINO to extract content, can we obtain a style transfer that is robust to distortions of content images?
  \item Does DINO's ability to capture an image's global property from local pieces give it more robustness as a style encoder?
\end{enumerate}


\section{Related Works}



\section{Method}

We have four different idea for bringing the success of the DINO method to the domain of style transfer.

\subsection{Frozen DINO Content Encoder}

We replace the content encoder with a transformer trained by DINO and then train the style and decoders using the regular style transfer training paradigm. The idea being that the DINO models robust features vectors may act as powerful abstractions of the information that can be decoded with the new style.

\subsection{DINO Weight Initialized Content Encoder}

We use a transformer trained by DINO as the initial weights for the content encoder but we run the style transfer training paradigm on both encoders and the decoder, effectively using the weights from DINO as initial weights. We expect this to converge to a different optima because transformers have many local optima. We hope that the robust abstractions from the DINO training process lead to better style transfer.

\subsection{DINO Training for Encoders}



\subsection{Modified DINO Training for Encoders}



\medskip

% Our current sources
\nocite{*}

\bibliography{bib}

\end{document}